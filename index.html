<!DOCTYPE HTML>
<html lang="en">

<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">


  <title>Yucheng Shi</title>
  
  <meta name="author" content="Yucheng Shi">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!--<link rel="icon" type="image/svg+xml" href="images/University_of_Georgia_seal.svg">-->
  <link rel="alternate icon" type="image/png" href="images/UGA_CS.png">

  <!-- <script src=”main.js” defer></script> -->
</head>

<body>
<!-- 
<div class="topnav" id="myTopnav">
  <a href="#Home">Home</a>
  <a href="#Research">Research</a>
  <a href="#Experience">Experience</a>
  <a href="#Education">Education</a>
  <a href="#Misc">Misc</a>
  <a href="javascript:void(0);" class="icon" onclick="myFunction()">
    <i class="fa fa-bars"></i>
  </a>
</div>

<script>
  function myFunction() {
    var x = document.getElementById("myTopnav");
    if (x.className === "topnav") {
      x.className += " responsive";
    } else {
      x.className = "topnav";
    }
  }
</script> -->
  <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:10px">
      <td style="padding:10px">

      <section id="Home" style="padding-top:2vh;padding-bottom:1vh;">       
              <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tr style="padding:10px">
                  <td style="padding:2.5%;width:63%;vertical-align:middle;line-height: 150%;">
                    <p style="text-align:center">
                      <name>Yucheng Shi - 史淯城</name>
                    </p>
                    <p>
                      I am a third-year Ph.D. student at the University of Georgia, under the mentorship of Prof. <a href="https://cobweb.cs.uga.edu/~ninghaoliu/">Ninghao Liu</a>. My research is centered around the exciting fields of <strong>Responsible AI</strong>, with a primary goal to craft interpretable deep learning models that produce reliable and verified outputs. I am also interested in <strong>AI4Med</strong> and am currently a data scientist intern (remote) at <a href="https://camca.mgh.harvard.edu/about-us/">CAMCA</a>, Harvard Medical School. My specific areas of research include:
                      <ul>
                          <li><strong>Interpretable AI System Design:</strong> <a href="https://arxiv.org/abs/2403.19631">Retrieval Augmented Model Editing</a>, <a href="https://arxiv.org/abs/2309.16035">Medical RAG</a>, <a href="https://arxiv.org/abs/2305.03513">ChatGraph</a>, <a href="https://arxiv.org/abs/2308.09663">GiGaMAE</a>. </li>
                          <li><strong>Explainability and its utilization:</strong> <a href="https://arxiv.org/abs/2403.08946">XAI Usage with LLMs</a>, <a href="http://arxiv.org/abs/2307.01053">ENGAGE</a>, <a href="https://arxiv.org/abs/2310.10708">Explanation of Deep Visual Neurons</a>, <a href="https://arxiv.org/abs/2305.14582">XAI with Time Series</a>.</li>
                          <li><strong>Reliability and Safety:</strong> <a href="https://arxiv.org/abs/2303.12175">Black-box backdoor defense (ZIP).</a>  </li>
                          <li><strong>Medical Foundation Models:</strong> <a href="https://arxiv.org/abs/2408.11848">Radiology Llama 70B Post-training (tech report)</a>. </li>
                      </ul>
                    </p>
                    <p style="text-align:center">
                      <span style="white-space: nowrap;">
                        <i class="fa fa-envelope"></i> 
                        <a href="mailto:yucheng.shi@uga.edu">UGA</a> / 
                        <a href="mailto:yshi19@mgh.harvard.edu">Harvard</a>
                      </span>
                      &nbsp;&nbsp;|&nbsp;&nbsp;
                      <a href="https://www.linkedin.com/in/yucheng-shi-39a57a170/"><i class="fa fa-linkedin"></i> LinkedIn</a>
                      &nbsp;&nbsp;|&nbsp;&nbsp;
                      <a href="https://scholar.google.co.uk/citations?user=rIFRHvIAAAAJ&hl=en&oi=ao"><i class="fa fa-graduation-cap"></i> Google Scholar</a>
                      &nbsp;&nbsp;|&nbsp;&nbsp;
                      <a href="https://github.com/sycny"><i class="fa fa-github"></i> GitHub</a>
                      &nbsp;&nbsp;|&nbsp;&nbsp;
                      <a href="https://sycny.github.io/Yucheng_Shi_Resume_Fall_2024.pdf" target="_blank"><i class="fa fa-file-text-o"></i> CV</a>
                    </p>  
                  </td>
                  <td style="padding:2.5%;width:25%;max-width:25%">
                    <a href="images/info.jpeg"><img style="width:100%;max-width:100%" alt="info photo" src="images/info.jpeg" class="hoverZoomLink"></a>
                  </td>
                </tr>
              </tbody></table>
              </section>

        <section id="News">
            <h2 style="padding-bottom:1vh;"> News </h2>
            <table style="line-height:150%" class="table table-hover table-striped">
                <tr><td style="width:20%;">2024/07 - One paper accepted by CIKM 2024. </td></tr>
                <tr><td style="width:20%;">2024/06 - One paper accepted by AMIA 2024. </td></tr>
                <tr><td style="width:20%;">2024/06 - Give one tutorial about XAI and its medical application on <a href="https://ieeeichi2024.github.io/program.html">ICHI 2024. </td></tr>
                <tr><td style="width:20%;">2024/05 - Starting my remote internship at Harvard Medical School, advised by Dr. <a href="https://xiangli-shaun.github.io/index.html">Xiang Li. </td></tr>
                <tr><td style="width:20%;">2024/01 - One paper accepted by TheWenConf 2024. </td></tr>
                <!-- <tr><td style="width:20%;">2023/10 - One paper accepted by AAAI 2024. </td></tr> -->
                <!-- <tr><td style="width:20%;">2023/09 - One paper accepted by ICDMW 2023. </td></tr> -->
                <tr><td style="width:20%;">2023/09 - One paper accepted by NeurIPS 2023. </td></tr> 
                <!-- <tr><td style="width:20%;">2023/08 - One paper accepted by CIKM 2023. </td></tr> -->
                <!-- <tr><td style="width:20%;">2023/06 - One paper accepted by ECML-PKDD 2023. </td></tr> -->
                <tr><td style="width:20%;">2022/01 - I joined the DLGA lab at the University of Georgia as a research assistant. </td></tr>
            </table>
        </section>

        <br>

        <br>

        <section id="Research">
        <h2> Selected Papers </h2>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="text-indent:20px;width:100%;vertical-align:middle">
        <p>
          *Equal contribution.
        </p>
        </td>
        </tr>
        </tbody></table>

        <h3 style="text-indent:20px;color:#4A90E2;border-bottom:2px solid #4A90E2;padding-bottom:5px;">Interpretable AI System Design</h3>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <!-- Paper entries for Interpretable AI System Design -->
          <!-- (Paper entries omitted for brevity) -->
        

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:10px;width:20%;vertical-align:middle">
                <img src="images/RAE.png" alt="hpp" style="border-style: none" width="220">
              </td>
              <td style="padding:10px;width:80%;vertical-align:middle">
                <p>
                <papertitle>Retrieval-Enhanced Knowledge Editing for Multi-Hop Question Answering in Language Models</papertitle>
                </p>
                <strong>Yucheng Shi</strong>, Qiaoyu Tan, Xuansheng Wu, Shaochen Zhong, Kaixiong Zhou, Ninghao Liu.
                <br>
                <em><strong>(CIKM)</strong>, ACM International Conference on Information and Knowledge Management, 2024.</em>
                <br>
                <a href="https://arxiv.org/abs/2403.19631">[Paper]</a>
                <a href="https://github.com/sycny/RAE">[code]</a> 

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:10px;width:20%;vertical-align:middle">
                <img src="images/mededit.png" alt="hpp" style="border-style: none" width="220">
              </td>
              <td style="padding:10px;width:80%;vertical-align:middle">
                <p>
                <papertitle>MKRAG: Medical Knowledge Retrieval Augmented Generation for Medical Question Answering</papertitle>
                </p>
                <strong>Yucheng Shi<sup>*</sup></strong>, Shaochen Xu<sup>*</sup>, Tianze Yang<sup>*</sup>, Zhengliang Liu, Tianming Liu, Quanzheng Li, Xiang Li, Ninghao Liu.
                <br>
                <em><strong>(AMIA)</strong>, American Medical Informatics Association Annual Symposium, 2024.</em>
                <br>
                <a href="https://arxiv.org/abs/2309.16035">[Paper]</a>
                
          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:10px;width:20%;vertical-align:middle">
                <img src="images/gigamae.png" alt="hpp" style="border-style: none" width="220">
              </td>
              <td style="padding:10px;width:80%;vertical-align:middle">
                <p>
                <papertitle>GiGaMAE: Generalizable Graph Masked Autoencoder via Collaborative Latent Space Reconstruction</papertitle>
                </p>
                <strong>Yucheng Shi</strong>, Yushun Dong, Qiaoyu Tan, Jundong Li, Ninghao Liu.
                <br>
                <em><strong>(CIKM)</strong>, ACM International Conference on Information and Knowledge Management, 2023.</em>
                <br>
                <a href="https://dl.acm.org/doi/10.1145/3583780.3614894">[Paper]</a>
                <a href="https://github.com/sycny/GiGaMAE">[code]</a> 
                
          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:10px;width:20%;vertical-align:middle">
                <img src="images/ChatGraph.png" alt="hpp" style="border-style: none" width="220">
              </td>
              <td style="padding:10px;width:80%;vertical-align:middle">
                <p>
                <papertitle>ChatGraph: Interpretable Text Classification by Converting ChatGPT Knowledge to Graphs</papertitle>
                </p>
                <strong>Yucheng Shi<sup>*</sup></strong>, Hehuan Ma<sup>*</sup>, Wenliang Zhong<sup>*</sup>, Qiaoyu Tan, Gengchen Mai, Xiang Li, Tianming Liu, Junzhou Huang.
                <br>
                <em><strong>(ICDMW)</strong>, International Workshop on Learning with Knowledge Graphs @ ICDM2023, 2023.</em>
                <br>
                <a href="https://arxiv.org/abs/2305.03513">[Paper]</a>
                <a href="https://github.com/sycny/ChatGraph">[code]</a> 
        </tbody></table>


        
        <h3 style="text-indent:20px;color:#50C878;border-bottom:2px solid #50C878;padding-bottom:5px;">Reliability and Safety</h3>  

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <!-- Paper entries for Reliability and Safety -->
          <!-- (Paper entries omitted for brevity) -->
         

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:10px;width:20%;vertical-align:middle">
                <img src="images/ZIP.png" alt="hpp" style="border-style: none" width="220">
              </td>
              <td style="padding:10px;width:80%;vertical-align:middle">
                <p>
                <papertitle>Black-box Backdoor Defense via Zero-shot Image Purification</papertitle>
                </p>
                <strong>Yucheng Shi</strong>, Mengnan Du, Xuansheng Wu, Zihan Guan, Jin Sun, Ninghao Liu.
                <br>
                <em><strong>(NeurIPS)</strong>, Thirty-seventh Conference on Neural Information Processing Systems, 2023.</em>
                <br>
                <a href="https://arxiv.org/abs/2303.12175">[Paper]</a>
                <a href=" https://github.com/sycny/ZIP">[code]</a>  
        </tbody></table>
          
        <h3 style="text-indent:20px;color:#F39C12;border-bottom:2px solid #F39C12;padding-bottom:5px;">Explainability and its utilization</h3> 

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <!-- Paper entries for Explainability and its utilization -->
          <!-- (Paper entries omitted for brevity) -->
        

           <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:10px;width:20%;vertical-align:middle">
                <img src="images/usableai.png" alt="hpp" style="border-style: none" width="220">
              </td>
              <td style="padding:10px;width:80%;vertical-align:middle">
                <p>
                <papertitle>Usable XAI: 10 Strategies Towards Exploiting Explainability in the LLM Era</papertitle>
                </p>
                Xuansheng Wu<sup>*</sup>, Haiyan Zhao<sup>*</sup>, Yaochen Zhu<sup>*</sup>, <strong>Yucheng Shi<sup>*</sup></strong>, Fan Yang, Tianming Liu, Xiaoming Zhai, Wenlin Yao, Jundong Li, Mengnan Du, Ninghao Liu.	
                <br>
                <em><strong>(Preprints)</strong></em>
                <br>
                <a href="https://arxiv.org/abs/2403.08946">[Paper]</a>
                <a href="https://github.com/JacksonWuxs/UsableXAI_LLM">[code]</a>
                
           <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:10px;width:20%;vertical-align:middle">
                <img src="images/Quantifying_Multilingual.png" alt="hpp" style="border-style: none" width="220">
              </td>
              <td style="padding:10px;width:80%;vertical-align:middle">
                <p>
                <papertitle>Quantifying Multilingual Performance of Large Language Models Across Languages</papertitle>
                </p>
                Zihao Li, <strong>Yucheng Shi</strong>, Zirui Liu, Fan Yang, Ali Payani, Ninghao Liu, Mengnan Du.	
                <br>
                <em><strong>(Preprints)</strong></em>
                <br>
                <a href="https://arxiv.org/abs/2404.11553">[Paper]</a>                
                
           <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:10px;width:20%;vertical-align:middle">
                <img src="images/aaai_abstract.png" alt="hpp" style="border-style: none" width="220">
              </td>
              <td style="padding:10px;width:80%;vertical-align:middle">
                <p>
                <papertitle>Automated Natural Language Explanation of Deep Visual Neurons with Large Models</papertitle>
                </p>
                Chenxu Zhao, Wei Qian, <strong>Yucheng Shi</strong>, Mengdi Huai, Ninghao Liu.	
                <br>
                <em><strong>(AAAI Student Program)</strong>, AAAI-24 Student Program, 2024.</em>
                <br>
                <a href="https://arxiv.org/abs/2310.10708">[Paper]</a>
          
           <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:10px;width:20%;vertical-align:middle">
                <img src="images/time_series_model.png" alt="hpp" style="border-style: none" width="220">
              </td>
              <td style="padding:10px;width:80%;vertical-align:middle">
                <p>
                <papertitle>Interpretation of Time-Series Deep Models: A Survey</papertitle>
                </p>
                Ziqi Zhao<sup>*</sup>, <strong>Yucheng Shi<sup>*</sup></strong>, Shushan Wu<sup>*</sup>, Fan Yang, Wenzhan Song, Ninghao Liu.
                <br>
                  <strong>(Preprints)</strong><!--<em><strong>(ICDMW)</strong>, International Workshop on Learning with Knowledge Graphs @ ICDM2023, 2023.</em>-->
                <br>
                <a href="https://arxiv.org/abs/2305.14582">[Paper]</a>
                <a href="https://github.com/astrajoan/sequential-learning-interpretation">[code]</a> 
                
           <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:10px;width:20%;vertical-align:middle">
                <img src="images/ENGAGE.png" alt="hpp" style="border-style: none" width="220">
              </td>
              <td style="padding:10px;width:80%;vertical-align:middle">
                <p>
                <papertitle>ENGAGE: Explanation Guided Data Augmentation for Graph Representation Learning</papertitle>
                </p>
                <strong>Yucheng Shi</strong>, Kaixiong Zhou, Ninghao Liu.
                <br>
                <em><strong>(ECML-PKDD)</strong>, European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, 2023.</em>
                <br>
                <a href="http://arxiv.org/abs/2307.01053">[Paper]</a>
                <a href="https://github.com/sycny/ENGAGE">[code]</a> 
        </tbody></table>


        <h3 style="text-indent:20px;color:#8E44AD;border-bottom:2px solid #8E44AD;padding-bottom:5px;">Recommendation System</h3>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">  
              <td style="padding:10px;width:20%;vertical-align:middle">
                  <img src="images/llm_rec.png" alt="hpp" style="border-style: none" width="220">
                </td>
                <td style="padding:10px;width:80%;vertical-align:middle">
                  <p>
                  <papertitle>Could Small Language Models Serve as Recommenders? Towards Data-centric Cold-Start Recommendation</papertitle>
                  </p>
                   Xuansheng Wu, Huachi Zhou, <strong>Yucheng Shi</strong>, Wenlin Yao, Xiao Huang, Ninghao Liu.
                  <br>
                    <em><strong>(WWW)</strong>, The Web Conference, 2024.</em>
                  <br>
                  <a href="https://arxiv.org/abs/2306.17256">[Paper]</a>
                  <a href="https://github.com/JacksonWuxs/PromptRec">[code]</a> 
        </tbody></table>
        </section>

        <br>
                
        <section id="Teaching">
        <h2 style="padding-bottom:1vh;">Teaching</h2>
        <table style="line-height:150%" class="table table-hover table-striped">
          <tr><td style="width:20%;">Teaching Assistant of CSCI4380/6380 Data Mining and CSCI4370/6370 Database Management, University of Georgia, Spring 2024</td></tr>
          <tr><td style="width:20%;">Teaching Assistant of CSCI4380/6380 Data Mining (Two Sessions), University of Georgia, Fall 2023</td></tr>
          <tr><td style="width:20%;">Teaching Assistant of CSCI4380/6380 Data Mining, University of Georgia, Spring 2023</td></tr>
          <tr><td style="width:20%;">Teaching Assistant of CSCI4360/6360 Data Science, University of Georgia, Fall 2022</td></tr>
        </table> 
        </section>
        
        <br>

        <section id="Miscellaneous">
          <h2 style="padding-bottom:1vh;">Miscellaneous</h2>
          <div class="row">
            <div class="col-md-8">
              <p>
                Outside of research, I enjoy photography as a way to capture and appreciate life's small, beautiful moments. My camera helps me celebrate the everyday joys that surround us.              
                <a href="https://www.flickr.com/photos/157896273@N06/" class="btn btn-primary" target="_blank">
                <i class="fa fa-flickr"></i> My Flickr.
                </a>
            </div>
          </div>
        </section>

        <br>

      </td>
    </tr>
  </table>
</body>

</html>
